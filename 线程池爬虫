# 按照网页来获取大类，形成文件夹，然后在去修改数字，获取每一个图集，最后获取
# 返回404即为结束
# wj不能定义为全局变量，否则在多线程来回切换时，wj的值会变得混乱，导致执行出现问题,url同理
# 对xh进行线程，就不能对shouye和qiyu再使用线程限制。不对他们使用线程限制，那么他们的访问网址行为会在当前线程运行，如果对他们使用线程限制，那么他们就会开启新的线程去运行，又因为他们处在xh线程中，若xh线程没结束，那么他们就得不到线程，但要想xh结束，又必须运行他们才行，就会导致程序永远处于等待当中。协程同理
import concurrent.futures
import gc
import os
import re
import socket
import sys
import threading
import time
import requests
import urllib3
from bs4 import BeautifulSoup
from lxml import etree
from concurrent.futures import ThreadPoolExecutor

from retry import retry

@retry(exceptions=(
        TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
        requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError),
    tries=30, delay=5)
def fangwenshouye(url):
    url1 = url + f'.html'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.64'
    }
    resp1 = requests.get(url1, headers=headers, timeout=6)
    resp1.encoding = 'utf-8'
    return resp1
@retry(exceptions=(
        TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
        requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError),
    tries=10, delay=5)
def shouye(k, url):

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.64'
    }

    resp1=fangwenshouye(url)
    if resp1.status_code == 404:
        print('当前网址不存在', k)
        str(k)
        with open('C:/chucuo/wzry/' + '404网址' + '.txt', mode='a+') as bucunzai:
            bucunzai.write(f'当前网址不存在：{k}' + '\n')
        # pool_sema.release()  # 解除线程数限制
        return

    try:


        tuming = etree.HTML(resp1.text).xpath('/html/body/div[2]/h1/text()')  # 获取图片名字
        tuming_s = str(tuming).replace('\\', '-').replace('/', '-').replace(':', '-').replace('*', '-').replace('?',
                                                                                                                '-').replace(
            '\"', '-').replace('<', '-').replace('>', '-').replace('|', '-')
        print('当前正在爬取' + tuming_s)



        # wj不能定义为全局变量，否则在多线程来回切换时，wj的值会变得混乱，导致执行出现问题
        wj = f'C:/wzry/{k}+{tuming_s}/'  # 把文件夹名定义为全局变量，让qiyuye函数使用

        tu_l = etree.HTML(resp1.text).xpath('/html/body/div[2]/div[3]/a/p')  # 获取所有p标签
        if tu_l!=[]: #同一界面有多个图（此界面下表示为有多个p标签）

            a = 1
            for tu in tu_l:
                tutu = tu.xpath('./img/@src')  # 遍历p标签的img标签下的src元素，@是获取元素值的意思
                tututu = str(tutu[0])  # 把列表转换为字符串，否则request.get无法识别
                print(tututu)
                tu0 = requests.get(tututu, headers=headers, timeout=6).content  # 获取图片字节文件
                os.mkdir(f'C:/wzry/{k}+{tuming_s}/')

                with open(wj + tuming_s + f'编号{a}' + '.jpg', mode='wb') as f:  # 为了防止转义，python可以使用/表示win路径
                    f.write(tu0)
                time.sleep(0.3)
                a = a + 1
        else: #同一界面只有一张图
            tu_l = re.compile(r'<div class="text-center mb-4"><a href=".*?">.*?<img.*?src="(?P<lj>.*?)".*?</div>',
                              re.S)  # 正则提取图片下载地址
            tu = tu_l.finditer(resp1.text)
            tuming = etree.HTML(resp1.text).xpath('/html/body/div[2]/h1/text()')  # 获取图片名字
            tuming_s = str(tuming).replace('\\', '-').replace('/', '-').replace(':', '-').replace('*', '-').replace('?',
                                                                                                                    '-').replace(
                '\"', '-').replace('<', '-').replace('>', '-').replace('|', '-')
            print('当前正在爬取' + tuming_s)
            for i in tu:
                print(i.group('lj'))
            tu0 = requests.get(i.group('lj'), headers=headers, timeout=6).content  # 获取图片字节文件
            os.mkdir(f'C:/wzry/{k}+{tuming_s}/')
            with open(wj + tuming_s + '.jpg', mode='wb') as f:  # 为了防止转义，python可以使用/表示win路径
                f.write(tu0)
            time.sleep(0.3)
        # pool_sema.release() #解除线程数限制
        qiyuye(k, wj, url)
    except(TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
           requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError):
        raise
    except:
        print("当前图集未爬取到" + tuming_s)
        os.mkdir(f'C:/wzry/{k}+{tuming_s}/')
        # wj不能定义为全局变量，否则在多线程来回切换时，wj的值会变得混乱，导致执行出现问题
        wj = f'C:/wzry/{k}+{tuming_s}/'
        with open(f'C:/wzry/{k}+{tuming_s}/' + tuming_s + '.txt', mode='a+') as cuo:
            cuo.write(f'当前首页未爬取到{tuming_s},当前数字：{k}，编号没传')
        with open(f'C:/chucuo/wzry/' + str(k) + tuming_s + '.txt', mode='a+') as cuo2:
            cuo2.write(f'当前首页未爬取到{tuming_s},当前数字：{k}，编号没传')

        qiyuye(k, wj, url)
    finally:
        resp1.close()



@retry(exceptions=(
        TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
        requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError),
    tries=10, delay=5)
def huoqutu(a, head, tuming, wj, bianhao=None):
    b = bianhao
    tu0_22 = requests.get(a, headers=head, timeout=6).content  # 获取图片字节文件
    with open(wj + tuming + f'编号{b}' + '.jpg', mode='wb') as f:  # 为了防止转义，python可以使用/表示win路径
        f.write(tu0_22)

@retry(exceptions=(
        TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
        requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError),
    tries=10, delay=5)
def fangwenqiyu(url,yeshu):
    url2 = url + f'_{yeshu}.html'

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.64'
    }
    resp2 = requests.get(url2, headers=headers, timeout=10)
    resp2.encoding = 'utf-8'
    return resp2

@retry(exceptions=(
        TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
        requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError),
    tries=10, delay=5)
def qiyu(yeshu, k, wj, url):

    try:
        print('准备爬取')

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.64'
        }

        resp2=fangwenqiyu(url,yeshu)
        print('已获取网页')
        if resp2.status_code == 404:
            return 123


        tuming = etree.HTML(resp2.text).xpath('/html/body/div[2]/h1/text()')  # 获取图片名字
        tuming_s = str(tuming).replace('\\', '-').replace('/', '-').replace(':', '-').replace('*', '-').replace('?',
                                                                                                                '-').replace(
            '\"', '-').replace('<', '-').replace('>', '-').replace('|', '-')
        print('当前正在爬取' + tuming_s)

        # # 下载链接
        tu_l = etree.HTML(resp2.text).xpath('/html/body/div[2]/div[3]/a/p')  # 获取所有p标签
        if tu_l!=[]:

            a = 1
            for tu in tu_l:
                tutu1 = tu.xpath('./img/@src')  # 遍历p标签的img标签下的src元素，@是获取元素值的意思
                tututu1 = str(tutu1[0])
                print(tututu1)
                try:
                    try:
                        huoqutu(a=tututu1, head=headers, tuming=tuming_s, wj=wj, bianhao=a)  # 防止网站的服务器超时
                        a = a + 1
                    except(TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
                           requests.exceptions.ReadTimeout):
                        with open(wj + tuming_s + '.txt', mode='a+') as tupianmeishuju:
                            tupianmeishuju.write(f'当前图片已无法找到数据--{tuming_s}，编号没传')
                            print(f'当前图片已无法找到数据--{tuming_s}，编号没传')



                except:
                    with open(wj + tuming_s + '.txt', mode='a+') as tupianmeishuju:
                        tupianmeishuju.write(f'当前图片已无法找到数据--{tuming_s}，编号没传')
                        print(f'当前图片已无法找到数据--{tuming_s}，编号没传')
        else:
            tu_l22 = re.compile(r'<div class="text-center mb-4"><a href=".*?">.*?<img.*?src="(?P<lj>.*?)".*?</div>',
                                re.S)  # 正则提取图片下载地址
            tu22 = tu_l22.finditer(resp2.text)
            for i in tu22:
                print(i.group('lj'))
            try:
                try:
                    huoqutu(a=i.group('lj'), head=headers, tuming=tuming_s,wj=wj)  # 防止网站的服务器超时
                except(TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
                       requests.exceptions.ReadTimeout):
                    with open(wj + tuming_s + '.txt', mode='a+') as tupianmeishuju:
                        tupianmeishuju.write(f'当前图片已无法找到数据--{tuming_s}')
                        print(f'当前图片已无法找到数据--{tuming_s}')

            except(TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
                   requests.exceptions.ReadTimeout):
                raise  # 向上抛出超时异常，好让retry生效

            except:
                with open(wj + tuming_s + '.txt', mode='a+') as tupianmeishuju:
                    tupianmeishuju.write(f'当前图片已无法找到数据--{tuming_s}')
                    print(f'当前图片已无法找到数据--{tuming_s}')
    except(TimeoutError, socket.timeout, UnboundLocalError, urllib3.exceptions.ReadTimeoutError,
           requests.exceptions.ReadTimeout,requests.exceptions.ConnectionError):
        raise
    except:
        with open(wj + tuming_s + '.txt', mode='a+') as tupianmeishuju:
            tupianmeishuju.write(f'当前图片已无法找到数据--{tuming_s}')
            print(f'当前图片已无法找到数据--{tuming_s}')
    finally:
        resp2.close()

    time.sleep(0.3)


def qiyuye(k, wj, url):
    for yeshu in range(2, 800):
        if qiyu(yeshu, k, wj, url) == 123:  # 调用的同时做出判断，若返回123，则证明可以结束循环了
            break


def xh(k):

    url = f'https://xxxxx/{k}'
    print('当前数字是' + str(k))
    shouye(k, url)
    print('爬取完毕')

    gc.collect()  # 清理内存


if __name__ == '__main__':
    i = 1
    k = [] #k为要传的参数值
    while i < 9000:
        k.append(i)
        i = i + 1
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as pool:  # 创建线程池,max_workers为最大线程数，如果线程数设置的比较大，而电脑性能跟不上的话，有些io操作就会被跳过，不进行输入输出。协程同理
        # 利用pool.map使用线程
        pool.map(xh, k)  # 第一个参数为函数，不能带括号，第二个参数是要传入函数的系列值，是一个列表
